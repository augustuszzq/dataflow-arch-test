INFO:numexpr.utils:Note: detected 128 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
INFO:numexpr.utils:Note: NumExpr detected 128 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
INFO:numexpr.utils:NumExpr defaulting to 8 threads.
WARNING:root:Config loaded using yaml path without using config class
2024-06-11 21:03:58,995 WARNING:   Adam got 1 unexpected and unused parameters: ['momentum'].
Please ensure that you specified the correct parameters:
Adam(params: Iterable[torch.nn.parameter.Parameter], lr: float = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-06, weight_decay: float = 0.0, amsgrad: bool = False)
Passing in unused parameters is deprecated behaviour and support for it will be removed in a future release.
2024-06-11 21:03:59,022 INFO:   Effective batch size is 64.
2024-06-11 21:03:59,303 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in "/home/kevienzzq/mixed_precision/output/model_dir_mnist" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.
2024-06-11 21:03:59,304 INFO:   No checkpoints were found in "/home/kevienzzq/mixed_precision/output/model_dir_mnist".
2024-06-11 21:03:59,304 INFO:   No checkpoint was provided. Using randomly initialized model parameters.
2024-06-11 21:03:59,333 WARNING:   Passing an absolute path as the compile directory may lead to undesirably long paths as the directory is used on the server side, not on the client side. Please consider passing in a relative directory instead.
2024-06-11 21:04:02,838 INFO:   Compiling the model. This may take a few minutes.
2024-06-11 21:04:02,839 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-06-11 21:04:04,473 INFO:   Initiating a new image build job against the cluster server.
2024-06-11 21:04:04,479 INFO:   Custom worker image build is disabled from server.
2024-06-11 21:04:04,479 WARNING:   Passing an absolute path as the compile directory may lead to undesirably long paths as the directory is used on the server side, not on the client side. Please consider passing in a relative directory instead.
2024-06-11 21:04:04,480 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-06-11 21:04:04,574 INFO:   Initiating a new compile wsjob against the cluster server.
2024-06-11 21:04:04,587 INFO:   compile job id: wsjob-zgprmtyrmb3mxtkobn7zfa, remote log path: /n1/wsjob/workdir/job-operator/wsjob-zgprmtyrmb3mxtkobn7zfa
2024-06-11 21:04:14,606 INFO:   Poll ingress status: Waiting for job running, current job status: Initializing, msg: job initializing with config generation. 
2024-06-11 21:04:24,609 INFO:   Poll ingress status: Waiting for all Coordinator pods to be running, current running: 0/1. 
2024-06-11 21:04:44,633 INFO:   Poll ingress status: Waiting for job ingress readiness.
2024-06-11 21:05:04,657 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-06-11 21:05:05,604 INFO:   Pre-optimization transforms...
2024-06-11 21:05:05,659 INFO:   Optimizing layouts and memory usage...
2024-06-11 21:05:05,660 INFO:   Gradient accumulation enabled
2024-06-11 21:05:05,660 INFO:   Gradient accumulation trying micro batch size 4...
2024-06-11 21:05:05,724 INFO:   Exploring floorplans
2024-06-11 21:06:38,246 INFO:   Exploring data layouts
2024-06-11 21:06:40,253 INFO:   Optimizing memory usage
2024-06-11 21:07:00,520 INFO:   Gradient accumulation trying micro batch size 16...
2024-06-11 21:07:00,572 INFO:   Exploring floorplans
2024-06-11 21:08:43,123 INFO:   Exploring data layouts
2024-06-11 21:08:44,450 INFO:   Optimizing memory usage
2024-06-11 21:09:03,200 INFO:   Gradient accumulation trying micro batch size 8...
2024-06-11 21:09:03,252 INFO:   Exploring floorplans
2024-06-11 21:10:44,204 INFO:   Exploring data layouts
2024-06-11 21:10:45,917 INFO:   Optimizing memory usage
2024-06-11 21:11:07,551 INFO:   Gradient accumulation trying micro batch size 32...
2024-06-11 21:11:07,604 INFO:   Exploring floorplans
2024-06-11 21:12:47,504 INFO:   Exploring data layouts
2024-06-11 21:12:48,992 INFO:   Optimizing memory usage
2024-06-11 21:13:06,090 INFO:   Exploring floorplans
2024-06-11 21:14:45,864 INFO:   Exploring data layouts
2024-06-11 21:14:47,047 INFO:   Optimizing memory usage
2024-06-11 21:15:05,706 INFO:   No benefit from gradient accumulation expected. Compile will proceed at original per-box batch size 64 with 5 lanes
2024-06-11 21:15:05,707 INFO:   Post-layout optimizations...
2024-06-11 21:15:05,771 INFO:   Allocating buffers...
2024-06-11 21:15:05,785 INFO:   Code generation...
2024-06-11 21:15:12,848 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_7042520686067781043
2024-06-11 21:15:12,873 INFO:   Compile was successful!
2024-06-11 21:15:12,873 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.
2024-06-11 21:15:12,874 INFO:   Waiting for weight initialization to complete
2024-06-11 21:15:12,966 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.
2024-06-11 21:15:13,069 INFO:   Initiating a new execute wsjob against the cluster server.
2024-06-11 21:15:13,091 INFO:   execute job id: wsjob-djbnahvbcudzwszhjswcru, remote log path: /n1/wsjob/workdir/job-operator/wsjob-djbnahvbcudzwszhjswcru
2024-06-11 21:15:23,117 INFO:   Poll ingress status: Waiting for job running, current job status: Initializing, msg: job initializing with config generation. 
2024-06-11 21:15:33,130 INFO:   Poll ingress status: Waiting for all Worker pods to be running, current running: 0/1. 
2024-06-11 21:15:43,138 INFO:   Poll ingress status: Waiting for all Activation pods to be running, current running: 0/33. 
2024-06-11 21:15:53,148 INFO:   Poll ingress status: Waiting for all Weight pods to be running, current running: 0/24. 
2024-06-11 21:16:03,161 INFO:   Poll ingress status: Waiting for all Activation pods to be running, current running: 0/33. 
2024-06-11 21:16:13,170 INFO:   Poll ingress status: Waiting for all Command pods to be running, current running: 0/1. 
2024-06-11 21:16:23,180 INFO:   Poll ingress status: Waiting for all Activation pods to be running, current running: 0/33. 
2024-06-11 21:16:43,200 INFO:   Poll ingress status: Waiting for all Weight pods to be running, current running: 0/24. 
2024-06-11 21:16:53,210 INFO:   Poll ingress status: Waiting for all Activation pods to be running, current running: 23/33. 
2024-06-11 21:17:13,227 INFO:   Poll ingress status: Waiting for all Weight pods to be running, current running: 18/24. 
2024-06-11 21:17:23,249 INFO:   Ingress is ready: Job ingress ready, poll ingress success.
2024-06-11 21:17:23,413 INFO:   Preparing to execute using 1 CSX
2024-06-11 21:19:37,387 INFO:   About to send initial weights
../../../../cerebras/modelzoo/common/input_utils.py:175: UserWarning: Gradient accumulation will search for a well-performing micro batch size based on internal performance models, which can lead to an increased compile time. Also, this search is limited to dividers of model global batch size 64.
You can specify your own micro batch size to reduce compile time or have our `Automatic Batch Exploration` tool do a thorough exploration for a more optimal micro batch size by doing the following in your `config.yaml` file:
1. Set the `micro_batch_size` option to your the desired value, if a preferred micro batch size is already known.
2. Set the `micro_batch_size` option to `explore`. This will perform a longer, broad search for an optimal micro batch size to maximize the performance of your run, regardless of current global batch size.
You can find more information on the `Automatic Batch Exploration` page on the Cerebras documentation site.
  warn(
2024-06-11 21:19:40,808 INFO:   Finished sending initial weights
2024-06-11 21:19:40,808 INFO:   Finalizing appliance staging for the run
2024-06-11 21:19:40,821 INFO:   Waiting for device programming to complete
2024-06-11 21:19:40,822 INFO:   Device programming is complete
2024-06-11 21:19:41,281 INFO:   Using network type: ROCE
2024-06-11 21:19:41,282 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...
2024-06-11 21:19:41,293 INFO:   Input workers have begun streaming input data
2024-06-11 21:19:42,432 INFO:   Appliance staging is complete
2024-06-11 21:19:42,432 INFO:   Beginning appliance run
2024-06-11 21:19:44,007 INFO:   | Train Device=CSX, Step=100, Loss=0.46954, Rate=4073.34 samples/sec, GlobalRate=4073.37 samples/sec
2024-06-11 21:19:45,542 INFO:   | Train Device=CSX, Step=200, Loss=0.46563, Rate=4130.33 samples/sec, GlobalRate=4120.29 samples/sec
2024-06-11 21:19:47,127 INFO:   | Train Device=CSX, Step=300, Loss=0.19388, Rate=4075.04 samples/sec, GlobalRate=4092.55 samples/sec
2024-06-11 21:19:48,718 INFO:   | Train Device=CSX, Step=400, Loss=0.16898, Rate=4043.39 samples/sec, GlobalRate=4074.76 samples/sec
2024-06-11 21:19:50,312 INFO:   | Train Device=CSX, Step=500, Loss=0.30620, Rate=4025.84 samples/sec, GlobalRate=4062.49 samples/sec
2024-06-11 21:19:51,916 INFO:   | Train Device=CSX, Step=600, Loss=0.15281, Rate=4004.97 samples/sec, GlobalRate=4050.41 samples/sec
2024-06-11 21:19:53,510 INFO:   | Train Device=CSX, Step=700, Loss=0.20038, Rate=4011.00 samples/sec, GlobalRate=4045.31 samples/sec
2024-06-11 21:19:55,124 INFO:   | Train Device=CSX, Step=800, Loss=0.12745, Rate=3983.65 samples/sec, GlobalRate=4035.15 samples/sec
2024-06-11 21:19:56,705 INFO:   | Train Device=CSX, Step=900, Loss=0.12702, Rate=4022.46 samples/sec, GlobalRate=4036.61 samples/sec
2024-06-11 21:19:58,311 INFO:   | Train Device=CSX, Step=1000, Loss=0.06440, Rate=3999.94 samples/sec, GlobalRate=4031.38 samples/sec
2024-06-11 21:19:59,924 INFO:   | Train Device=CSX, Step=1100, Loss=0.07774, Rate=3980.74 samples/sec, GlobalRate=4025.53 samples/sec
2024-06-11 21:20:01,649 INFO:   | Train Device=CSX, Step=1200, Loss=0.16902, Rate=3817.76 samples/sec, GlobalRate=3997.11 samples/sec
2024-06-11 21:20:03,270 INFO:   | Train Device=CSX, Step=1300, Loss=0.12621, Rate=3896.49 samples/sec, GlobalRate=3993.37 samples/sec
2024-06-11 21:20:04,896 INFO:   | Train Device=CSX, Step=1400, Loss=0.07913, Rate=3920.52 samples/sec, GlobalRate=3989.26 samples/sec
2024-06-11 21:20:06,553 INFO:   | Train Device=CSX, Step=1500, Loss=0.05055, Rate=3885.35 samples/sec, GlobalRate=3980.51 samples/sec
2024-06-11 21:20:08,134 INFO:   | Train Device=CSX, Step=1600, Loss=0.22741, Rate=3982.74 samples/sec, GlobalRate=3984.64 samples/sec
2024-06-11 21:20:09,700 INFO:   | Train Device=CSX, Step=1700, Loss=0.16943, Rate=4045.91 samples/sec, GlobalRate=3990.57 samples/sec
2024-06-11 21:20:11,290 INFO:   | Train Device=CSX, Step=1800, Loss=0.27422, Rate=4032.43 samples/sec, GlobalRate=3992.39 samples/sec
2024-06-11 21:20:12,802 INFO:   | Train Device=CSX, Step=1900, Loss=0.08498, Rate=4153.33 samples/sec, GlobalRate=4004.41 samples/sec
2024-06-11 21:20:14,336 INFO:   | Train Device=CSX, Step=2000, Loss=0.16684, Rate=4165.15 samples/sec, GlobalRate=4012.52 samples/sec
2024-06-11 21:20:15,856 INFO:   | Train Device=CSX, Step=2100, Loss=0.06428, Rate=4191.13 samples/sec, GlobalRate=4021.43 samples/sec
2024-06-11 21:20:17,390 INFO:   | Train Device=CSX, Step=2200, Loss=0.21265, Rate=4181.17 samples/sec, GlobalRate=4028.15 samples/sec
2024-06-11 21:20:18,949 INFO:   | Train Device=CSX, Step=2300, Loss=0.05486, Rate=4134.91 samples/sec, GlobalRate=4031.39 samples/sec
2024-06-11 21:20:20,566 INFO:   | Train Device=CSX, Step=2400, Loss=0.04006, Rate=4028.08 samples/sec, GlobalRate=4028.23 samples/sec
2024-06-11 21:20:22,168 INFO:   | Train Device=CSX, Step=2500, Loss=0.09569, Rate=4008.40 samples/sec, GlobalRate=4026.90 samples/sec
2024-06-11 21:20:23,758 INFO:   | Train Device=CSX, Step=2600, Loss=0.08389, Rate=4019.51 samples/sec, GlobalRate=4026.90 samples/sec
2024-06-11 21:20:25,395 INFO:   | Train Device=CSX, Step=2700, Loss=0.10985, Rate=3953.31 samples/sec, GlobalRate=4022.41 samples/sec
2024-06-11 21:20:26,980 INFO:   | Train Device=CSX, Step=2800, Loss=0.15224, Rate=4004.21 samples/sec, GlobalRate=4022.97 samples/sec
2024-06-11 21:20:28,635 INFO:   | Train Device=CSX, Step=2900, Loss=0.02008, Rate=3922.10 samples/sec, GlobalRate=4017.40 samples/sec
2024-06-11 21:20:30,313 INFO:   | Train Device=CSX, Step=3000, Loss=0.08575, Rate=3856.00 samples/sec, GlobalRate=4010.19 samples/sec
2024-06-11 21:20:31,923 INFO:   | Train Device=CSX, Step=3100, Loss=0.20616, Rate=3928.22 samples/sec, GlobalRate=4009.09 samples/sec
2024-06-11 21:20:33,541 INFO:   | Train Device=CSX, Step=3200, Loss=0.06633, Rate=3944.86 samples/sec, GlobalRate=4007.41 samples/sec
2024-06-11 21:20:35,113 INFO:   | Train Device=CSX, Step=3300, Loss=0.09511, Rate=4020.22 samples/sec, GlobalRate=4009.29 samples/sec
2024-06-11 21:20:36,744 INFO:   | Train Device=CSX, Step=3400, Loss=0.14978, Rate=3963.09 samples/sec, GlobalRate=4006.76 samples/sec
2024-06-11 21:20:38,291 INFO:   | Train Device=CSX, Step=3500, Loss=0.10966, Rate=4066.70 samples/sec, GlobalRate=4010.34 samples/sec
2024-06-11 21:20:39,923 INFO:   | Train Device=CSX, Step=3600, Loss=0.06343, Rate=3980.15 samples/sec, GlobalRate=4007.84 samples/sec
2024-06-11 21:20:41,532 INFO:   | Train Device=CSX, Step=3700, Loss=0.09744, Rate=3978.16 samples/sec, GlobalRate=4007.00 samples/sec
2024-06-11 21:20:43,115 INFO:   | Train Device=CSX, Step=3800, Loss=0.07369, Rate=4017.64 samples/sec, GlobalRate=4007.96 samples/sec
2024-06-11 21:20:44,703 INFO:   | Train Device=CSX, Step=3900, Loss=0.11099, Rate=4024.46 samples/sec, GlobalRate=4008.50 samples/sec
2024-06-11 21:20:46,303 INFO:   | Train Device=CSX, Step=4000, Loss=0.10090, Rate=4010.06 samples/sec, GlobalRate=4008.30 samples/sec
2024-06-11 21:20:47,885 INFO:   | Train Device=CSX, Step=4100, Loss=0.13945, Rate=4031.65 samples/sec, GlobalRate=4009.21 samples/sec
2024-06-11 21:20:49,469 INFO:   | Train Device=CSX, Step=4200, Loss=0.15994, Rate=4037.15 samples/sec, GlobalRate=4009.96 samples/sec
2024-06-11 21:20:51,087 INFO:   | Train Device=CSX, Step=4300, Loss=0.03134, Rate=3987.52 samples/sec, GlobalRate=4008.65 samples/sec
2024-06-11 21:20:52,693 INFO:   | Train Device=CSX, Step=4400, Loss=0.03769, Rate=3986.71 samples/sec, GlobalRate=4008.13 samples/sec
2024-06-11 21:20:54,284 INFO:   | Train Device=CSX, Step=4500, Loss=0.14001, Rate=4007.44 samples/sec, GlobalRate=4008.42 samples/sec
2024-06-11 21:20:55,886 INFO:   | Train Device=CSX, Step=4600, Loss=0.11917, Rate=4000.92 samples/sec, GlobalRate=4008.17 samples/sec
2024-06-11 21:20:57,459 INFO:   | Train Device=CSX, Step=4700, Loss=0.04858, Rate=4040.36 samples/sec, GlobalRate=4009.39 samples/sec
2024-06-11 21:20:59,056 INFO:   | Train Device=CSX, Step=4800, Loss=0.24065, Rate=4020.95 samples/sec, GlobalRate=4009.36 samples/sec
2024-06-11 21:21:00,641 INFO:   | Train Device=CSX, Step=4900, Loss=0.10529, Rate=4030.68 samples/sec, GlobalRate=4009.93 samples/sec
2024-06-11 21:21:02,237 INFO:   | Train Device=CSX, Step=5000, Loss=0.25861, Rate=4018.65 samples/sec, GlobalRate=4009.94 samples/sec
2024-06-11 21:21:02,238 INFO:   Saving checkpoint at step 5000
2024-06-11 21:21:06,489 INFO:   Saved checkpoint /home/kevienzzq/mixed_precision/output/model_dir_mnist/checkpoint_5000.mdl
2024-06-11 21:21:08,089 INFO:   | Train Device=CSX, Step=5100, Loss=0.13707, Rate=2263.69 samples/sec, GlobalRate=3810.71 samples/sec
2024-06-11 21:21:09,679 INFO:   | Train Device=CSX, Step=5200, Loss=0.03777, Rate=3320.72 samples/sec, GlobalRate=3814.62 samples/sec
2024-06-11 21:21:11,233 INFO:   | Train Device=CSX, Step=5300, Loss=0.06301, Rate=3799.09 samples/sec, GlobalRate=3819.93 samples/sec
2024-06-11 21:21:12,840 INFO:   | Train Device=CSX, Step=5400, Loss=0.04757, Rate=3909.46 samples/sec, GlobalRate=3822.83 samples/sec
2024-06-11 21:21:14,347 INFO:   | Train Device=CSX, Step=5500, Loss=0.19434, Rate=4110.57 samples/sec, GlobalRate=3829.75 samples/sec
2024-06-11 21:21:15,870 INFO:   | Train Device=CSX, Step=5600, Loss=0.13193, Rate=4166.31 samples/sec, GlobalRate=3835.84 samples/sec
2024-06-11 21:21:17,420 INFO:   | Train Device=CSX, Step=5700, Loss=0.09028, Rate=4143.90 samples/sec, GlobalRate=3840.63 samples/sec
2024-06-11 21:21:18,974 INFO:   | Train Device=CSX, Step=5800, Loss=0.08863, Rate=4129.30 samples/sec, GlobalRate=3845.11 samples/sec
2024-06-11 21:21:20,493 INFO:   | Train Device=CSX, Step=5900, Loss=0.02557, Rate=4179.89 samples/sec, GlobalRate=3850.82 samples/sec
2024-06-11 21:21:22,009 INFO:   | Train Device=CSX, Step=6000, Loss=0.14537, Rate=4204.11 samples/sec, GlobalRate=3856.45 samples/sec
2024-06-11 21:21:23,525 INFO:   | Train Device=CSX, Step=6100, Loss=0.17811, Rate=4215.17 samples/sec, GlobalRate=3861.94 samples/sec
2024-06-11 21:21:25,045 INFO:   | Train Device=CSX, Step=6200, Loss=0.01642, Rate=4212.30 samples/sec, GlobalRate=3867.10 samples/sec
2024-06-11 21:21:26,562 INFO:   | Train Device=CSX, Step=6300, Loss=0.15489, Rate=4215.67 samples/sec, GlobalRate=3872.21 samples/sec
2024-06-11 21:21:28,074 INFO:   | Train Device=CSX, Step=6400, Loss=0.14172, Rate=4226.71 samples/sec, GlobalRate=3877.39 samples/sec
2024-06-11 21:21:29,596 INFO:   | Train Device=CSX, Step=6500, Loss=0.08402, Rate=4212.50 samples/sec, GlobalRate=3882.02 samples/sec
2024-06-11 21:21:31,119 INFO:   | Train Device=CSX, Step=6600, Loss=0.03413, Rate=4207.32 samples/sec, GlobalRate=3886.52 samples/sec
2024-06-11 21:21:32,858 INFO:   | Train Device=CSX, Step=6700, Loss=0.02423, Rate=3891.32 samples/sec, GlobalRate=3883.28 samples/sec
2024-06-11 21:21:34,387 INFO:   | Train Device=CSX, Step=6800, Loss=0.16020, Rate=4066.75 samples/sec, GlobalRate=3887.39 samples/sec
2024-06-11 21:21:35,924 INFO:   | Train Device=CSX, Step=6900, Loss=0.05836, Rate=4124.99 samples/sec, GlobalRate=3891.13 samples/sec
2024-06-11 21:21:37,438 INFO:   | Train Device=CSX, Step=7000, Loss=0.13871, Rate=4186.68 samples/sec, GlobalRate=3895.56 samples/sec
2024-06-11 21:21:38,932 INFO:   | Train Device=CSX, Step=7100, Loss=0.07714, Rate=4245.73 samples/sec, GlobalRate=3900.56 samples/sec
2024-06-11 21:21:40,451 INFO:   | Train Device=CSX, Step=7200, Loss=0.09302, Rate=4226.05 samples/sec, GlobalRate=3904.58 samples/sec
2024-06-11 21:21:41,997 INFO:   | Train Device=CSX, Step=7300, Loss=0.06059, Rate=4173.88 samples/sec, GlobalRate=3907.61 samples/sec
2024-06-11 21:21:43,554 INFO:   | Train Device=CSX, Step=7400, Loss=0.15041, Rate=4135.47 samples/sec, GlobalRate=3910.21 samples/sec
2024-06-11 21:21:45,075 INFO:   | Train Device=CSX, Step=7500, Loss=0.11886, Rate=4179.62 samples/sec, GlobalRate=3913.92 samples/sec
2024-06-11 21:21:46,576 INFO:   | Train Device=CSX, Step=7600, Loss=0.04465, Rate=4229.79 samples/sec, GlobalRate=3918.14 samples/sec
2024-06-11 21:21:48,085 INFO:   | Train Device=CSX, Step=7700, Loss=0.10841, Rate=4237.48 samples/sec, GlobalRate=3922.04 samples/sec
2024-06-11 21:21:49,616 INFO:   | Train Device=CSX, Step=7800, Loss=0.06311, Rate=4202.52 samples/sec, GlobalRate=3925.13 samples/sec
2024-06-11 21:21:51,135 INFO:   | Train Device=CSX, Step=7900, Loss=0.13264, Rate=4209.01 samples/sec, GlobalRate=3928.53 samples/sec
2024-06-11 21:21:52,664 INFO:   | Train Device=CSX, Step=8000, Loss=0.04374, Rate=4195.68 samples/sec, GlobalRate=3931.57 samples/sec
2024-06-11 21:21:54,198 INFO:   | Train Device=CSX, Step=8100, Loss=0.21903, Rate=4180.04 samples/sec, GlobalRate=3934.34 samples/sec
2024-06-11 21:21:55,777 INFO:   | Train Device=CSX, Step=8200, Loss=0.10782, Rate=4105.19 samples/sec, GlobalRate=3935.77 samples/sec
2024-06-11 21:21:57,338 INFO:   | Train Device=CSX, Step=8300, Loss=0.00230, Rate=4101.07 samples/sec, GlobalRate=3937.65 samples/sec
2024-06-11 21:21:58,940 INFO:   | Train Device=CSX, Step=8400, Loss=0.13512, Rate=4038.43 samples/sec, GlobalRate=3938.34 samples/sec
2024-06-11 21:22:00,511 INFO:   | Train Device=CSX, Step=8500, Loss=0.00555, Rate=4058.84 samples/sec, GlobalRate=3939.87 samples/sec
2024-06-11 21:22:02,075 INFO:   | Train Device=CSX, Step=8600, Loss=0.03394, Rate=4078.37 samples/sec, GlobalRate=3941.57 samples/sec
2024-06-11 21:22:03,642 INFO:   | Train Device=CSX, Step=8700, Loss=0.01264, Rate=4082.90 samples/sec, GlobalRate=3943.17 samples/sec
2024-06-11 21:22:05,226 INFO:   | Train Device=CSX, Step=8800, Loss=0.05737, Rate=4057.64 samples/sec, GlobalRate=3944.25 samples/sec
2024-06-11 21:22:06,786 INFO:   | Train Device=CSX, Step=8900, Loss=0.03687, Rate=4084.04 samples/sec, GlobalRate=3945.95 samples/sec
2024-06-11 21:22:08,360 INFO:   | Train Device=CSX, Step=9000, Loss=0.01725, Rate=4072.47 samples/sec, GlobalRate=3947.24 samples/sec
2024-06-11 21:22:09,938 INFO:   | Train Device=CSX, Step=9100, Loss=0.13856, Rate=4063.64 samples/sec, GlobalRate=3948.42 samples/sec
2024-06-11 21:22:11,530 INFO:   | Train Device=CSX, Step=9200, Loss=0.02988, Rate=4036.63 samples/sec, GlobalRate=3949.17 samples/sec
2024-06-11 21:22:13,087 INFO:   | Train Device=CSX, Step=9300, Loss=0.01874, Rate=4081.69 samples/sec, GlobalRate=3950.85 samples/sec
2024-06-11 21:22:14,616 INFO:   | Train Device=CSX, Step=9400, Loss=0.01827, Rate=4144.42 samples/sec, GlobalRate=3953.21 samples/sec
2024-06-11 21:22:16,130 INFO:   | Train Device=CSX, Step=9500, Loss=0.15961, Rate=4193.10 samples/sec, GlobalRate=3955.90 samples/sec
2024-06-11 21:22:17,672 INFO:   | Train Device=CSX, Step=9600, Loss=0.02252, Rate=4167.36 samples/sec, GlobalRate=3957.83 samples/sec
2024-06-11 21:22:19,251 INFO:   | Train Device=CSX, Step=9700, Loss=0.08641, Rate=4098.67 samples/sec, GlobalRate=3958.78 samples/sec
2024-06-11 21:22:20,806 INFO:   | Train Device=CSX, Step=9800, Loss=0.03335, Rate=4109.19 samples/sec, GlobalRate=3960.33 samples/sec
2024-06-11 21:22:22,346 INFO:   | Train Device=CSX, Step=9900, Loss=0.14670, Rate=4137.21 samples/sec, GlobalRate=3962.21 samples/sec
2024-06-11 21:22:23,888 INFO:   | Train Device=CSX, Step=10000, Loss=0.13784, Rate=4144.91 samples/sec, GlobalRate=3964.01 samples/sec
2024-06-11 21:22:23,889 INFO:   Saving checkpoint at step 10000
2024-06-11 21:22:28,150 INFO:   Saved checkpoint /home/kevienzzq/mixed_precision/output/model_dir_mnist/checkpoint_10000.mdl
2024-06-11 21:22:29,714 INFO:   | Train Device=CSX, Step=10100, Loss=0.09441, Rate=2317.12 samples/sec, GlobalRate=3864.21 samples/sec
2024-06-11 21:22:31,231 INFO:   | Train Device=CSX, Step=10200, Loss=0.11135, Rate=3459.04 samples/sec, GlobalRate=3867.41 samples/sec
2024-06-11 21:22:32,756 INFO:   | Train Device=CSX, Step=10300, Loss=0.12061, Rate=3901.03 samples/sec, GlobalRate=3870.35 samples/sec
2024-06-11 21:22:34,298 INFO:   | Train Device=CSX, Step=10400, Loss=0.00659, Rate=4049.88 samples/sec, GlobalRate=3872.86 samples/sec
2024-06-11 21:22:35,843 INFO:   | Train Device=CSX, Step=10500, Loss=0.04530, Rate=4106.33 samples/sec, GlobalRate=3875.27 samples/sec
2024-06-11 21:22:37,346 INFO:   | Train Device=CSX, Step=10600, Loss=0.15508, Rate=4197.78 samples/sec, GlobalRate=3878.57 samples/sec
2024-06-11 21:22:38,873 INFO:   | Train Device=CSX, Step=10700, Loss=0.00783, Rate=4192.63 samples/sec, GlobalRate=3881.25 samples/sec
2024-06-11 21:22:40,395 INFO:   | Train Device=CSX, Step=10800, Loss=0.05556, Rate=4200.73 samples/sec, GlobalRate=3884.03 samples/sec
2024-06-11 21:22:41,933 INFO:   | Train Device=CSX, Step=10900, Loss=0.00887, Rate=4176.05 samples/sec, GlobalRate=3886.39 samples/sec
2024-06-11 21:22:43,479 INFO:   | Train Device=CSX, Step=11000, Loss=0.32461, Rate=4154.50 samples/sec, GlobalRate=3888.56 samples/sec
2024-06-11 21:22:45,008 INFO:   | Train Device=CSX, Step=11100, Loss=0.01581, Rate=4174.08 samples/sec, GlobalRate=3891.06 samples/sec
2024-06-11 21:22:46,540 INFO:   | Train Device=CSX, Step=11200, Loss=0.04274, Rate=4175.30 samples/sec, GlobalRate=3893.43 samples/sec
2024-06-11 21:22:48,058 INFO:   | Train Device=CSX, Step=11300, Loss=0.04148, Rate=4201.16 samples/sec, GlobalRate=3896.09 samples/sec
2024-06-11 21:22:49,611 INFO:   | Train Device=CSX, Step=11400, Loss=0.00774, Rate=4152.40 samples/sec, GlobalRate=3897.95 samples/sec
2024-06-11 21:22:51,143 INFO:   | Train Device=CSX, Step=11500, Loss=0.00605, Rate=4168.15 samples/sec, GlobalRate=3900.23 samples/sec
2024-06-11 21:22:52,643 INFO:   | Train Device=CSX, Step=11600, Loss=0.03732, Rate=4227.26 samples/sec, GlobalRate=3903.11 samples/sec
2024-06-11 21:22:54,196 INFO:   | Train Device=CSX, Step=11700, Loss=0.02408, Rate=4163.65 samples/sec, GlobalRate=3904.88 samples/sec
2024-06-11 21:22:55,778 INFO:   | Train Device=CSX, Step=11800, Loss=0.03470, Rate=4091.73 samples/sec, GlobalRate=3906.02 samples/sec
2024-06-11 21:22:57,354 INFO:   | Train Device=CSX, Step=11900, Loss=0.18092, Rate=4074.16 samples/sec, GlobalRate=3907.28 samples/sec
2024-06-11 21:22:58,923 INFO:   | Train Device=CSX, Step=12000, Loss=0.04533, Rate=4076.53 samples/sec, GlobalRate=3908.65 samples/sec
2024-06-11 21:23:00,491 INFO:   | Train Device=CSX, Step=12100, Loss=0.01337, Rate=4079.89 samples/sec, GlobalRate=3910.02 samples/sec
2024-06-11 21:23:02,057 INFO:   | Train Device=CSX, Step=12200, Loss=0.10043, Rate=4083.70 samples/sec, GlobalRate=3911.40 samples/sec
2024-06-11 21:23:03,622 INFO:   | Train Device=CSX, Step=12300, Loss=0.05686, Rate=4087.28 samples/sec, GlobalRate=3912.79 samples/sec
2024-06-11 21:23:05,226 INFO:   | Train Device=CSX, Step=12400, Loss=0.07288, Rate=4028.81 samples/sec, GlobalRate=3913.40 samples/sec
2024-06-11 21:23:06,789 INFO:   | Train Device=CSX, Step=12500, Loss=0.03650, Rate=4068.29 samples/sec, GlobalRate=3914.79 samples/sec
2024-06-11 21:23:08,379 INFO:   | Train Device=CSX, Step=12600, Loss=0.02007, Rate=4042.42 samples/sec, GlobalRate=3915.64 samples/sec
2024-06-11 21:23:09,947 INFO:   | Train Device=CSX, Step=12700, Loss=0.07264, Rate=4065.49 samples/sec, GlobalRate=3916.89 samples/sec
2024-06-11 21:23:11,495 INFO:   | Train Device=CSX, Step=12800, Loss=0.01399, Rate=4106.69 samples/sec, GlobalRate=3918.49 samples/sec
2024-06-11 21:23:12,982 INFO:   | Train Device=CSX, Step=12900, Loss=0.09072, Rate=4225.77 samples/sec, GlobalRate=3921.23 samples/sec
2024-06-11 21:23:14,499 INFO:   | Train Device=CSX, Step=13000, Loss=0.02364, Rate=4221.22 samples/sec, GlobalRate=3923.35 samples/sec
2024-06-11 21:23:16,003 INFO:   | Train Device=CSX, Step=13100, Loss=0.06479, Rate=4242.43 samples/sec, GlobalRate=3925.70 samples/sec
2024-06-11 21:23:17,571 INFO:   | Train Device=CSX, Step=13200, Loss=0.03614, Rate=4145.27 samples/sec, GlobalRate=3926.82 samples/sec
2024-06-11 21:23:19,091 INFO:   | Train Device=CSX, Step=13300, Loss=0.00418, Rate=4185.10 samples/sec, GlobalRate=3928.82 samples/sec
2024-06-11 21:23:20,614 INFO:   | Train Device=CSX, Step=13400, Loss=0.00556, Rate=4194.42 samples/sec, GlobalRate=3930.72 samples/sec
2024-06-11 21:23:22,149 INFO:   | Train Device=CSX, Step=13500, Loss=0.10313, Rate=4179.35 samples/sec, GlobalRate=3932.39 samples/sec
2024-06-11 21:23:23,649 INFO:   | Train Device=CSX, Step=13600, Loss=0.01870, Rate=4233.17 samples/sec, GlobalRate=3934.67 samples/sec
2024-06-11 21:23:25,144 INFO:   | Train Device=CSX, Step=13700, Loss=0.07233, Rate=4260.46 samples/sec, GlobalRate=3936.98 samples/sec
2024-06-11 21:23:26,662 INFO:   | Train Device=CSX, Step=13800, Loss=0.00789, Rate=4233.95 samples/sec, GlobalRate=3938.87 samples/sec
2024-06-11 21:23:28,235 INFO:   | Train Device=CSX, Step=13900, Loss=0.05770, Rate=4135.83 samples/sec, GlobalRate=3939.79 samples/sec
2024-06-11 21:23:29,750 INFO:   | Train Device=CSX, Step=14000, Loss=0.21680, Rate=4187.75 samples/sec, GlobalRate=3941.67 samples/sec
2024-06-11 21:23:31,285 INFO:   | Train Device=CSX, Step=14100, Loss=0.00327, Rate=4178.07 samples/sec, GlobalRate=3943.21 samples/sec
2024-06-11 21:23:32,767 INFO:   | Train Device=CSX, Step=14200, Loss=0.14598, Rate=4260.85 samples/sec, GlobalRate=3945.61 samples/sec
2024-06-11 21:23:34,323 INFO:   | Train Device=CSX, Step=14300, Loss=0.09130, Rate=4173.29 samples/sec, GlobalRate=3946.75 samples/sec
2024-06-11 21:23:35,851 INFO:   | Train Device=CSX, Step=14400, Loss=0.01552, Rate=4181.91 samples/sec, GlobalRate=3948.32 samples/sec
2024-06-11 21:23:37,384 INFO:   | Train Device=CSX, Step=14500, Loss=0.01844, Rate=4177.40 samples/sec, GlobalRate=3949.80 samples/sec
2024-06-11 21:23:38,895 INFO:   | Train Device=CSX, Step=14600, Loss=0.02045, Rate=4213.17 samples/sec, GlobalRate=3951.63 samples/sec
2024-06-11 21:23:40,439 INFO:   | Train Device=CSX, Step=14700, Loss=0.03406, Rate=4172.21 samples/sec, GlobalRate=3952.89 samples/sec
2024-06-11 21:23:41,965 INFO:   | Train Device=CSX, Step=14800, Loss=0.00099, Rate=4184.14 samples/sec, GlobalRate=3954.41 samples/sec
2024-06-11 21:23:43,546 INFO:   | Train Device=CSX, Step=14900, Loss=0.07868, Rate=4102.74 samples/sec, GlobalRate=3955.03 samples/sec
2024-06-11 21:23:45,095 INFO:   | Train Device=CSX, Step=15000, Loss=0.12881, Rate=4120.39 samples/sec, GlobalRate=3956.16 samples/sec
2024-06-11 21:23:45,095 INFO:   Saving checkpoint at step 15000
2024-06-11 21:23:49,365 INFO:   Saved checkpoint /home/kevienzzq/mixed_precision/output/model_dir_mnist/checkpoint_15000.mdl
2024-06-11 21:23:50,912 INFO:   | Train Device=CSX, Step=15100, Loss=0.01436, Rate=2308.28 samples/sec, GlobalRate=3889.30 samples/sec
2024-06-11 21:23:52,464 INFO:   | Train Device=CSX, Step=15200, Loss=0.00963, Rate=3397.89 samples/sec, GlobalRate=3890.76 samples/sec
2024-06-11 21:23:54,010 INFO:   | Train Device=CSX, Step=15300, Loss=0.00720, Rate=3842.98 samples/sec, GlobalRate=3892.29 samples/sec
2024-06-11 21:23:55,613 INFO:   | Train Device=CSX, Step=15400, Loss=0.01432, Rate=3932.51 samples/sec, GlobalRate=3892.92 samples/sec
2024-06-11 21:23:57,185 INFO:   | Train Device=CSX, Step=15500, Loss=0.05952, Rate=4016.46 samples/sec, GlobalRate=3894.03 samples/sec
2024-06-11 21:23:58,767 INFO:   | Train Device=CSX, Step=15600, Loss=0.04248, Rate=4034.07 samples/sec, GlobalRate=3894.96 samples/sec
2024-06-11 21:24:00,358 INFO:   | Train Device=CSX, Step=15700, Loss=0.02775, Rate=4025.87 samples/sec, GlobalRate=3895.74 samples/sec
2024-06-11 21:24:01,944 INFO:   | Train Device=CSX, Step=15800, Loss=0.02222, Rate=4032.46 samples/sec, GlobalRate=3896.60 samples/sec
2024-06-11 21:24:03,526 INFO:   | Train Device=CSX, Step=15900, Loss=0.01374, Rate=4039.40 samples/sec, GlobalRate=3897.49 samples/sec
2024-06-11 21:24:05,074 INFO:   | Train Device=CSX, Step=16000, Loss=0.00796, Rate=4096.91 samples/sec, GlobalRate=3898.90 samples/sec
2024-06-11 21:24:06,654 INFO:   | Train Device=CSX, Step=16100, Loss=0.00362, Rate=4069.53 samples/sec, GlobalRate=3899.81 samples/sec
2024-06-11 21:24:08,195 INFO:   | Train Device=CSX, Step=16200, Loss=0.07983, Rate=4119.92 samples/sec, GlobalRate=3901.28 samples/sec
2024-06-11 21:24:09,699 INFO:   | Train Device=CSX, Step=16300, Loss=0.02784, Rate=4200.12 samples/sec, GlobalRate=3903.26 samples/sec
2024-06-11 21:24:11,230 INFO:   | Train Device=CSX, Step=16400, Loss=0.04342, Rate=4189.19 samples/sec, GlobalRate=3904.85 samples/sec
2024-06-11 21:24:12,749 INFO:   | Train Device=CSX, Step=16500, Loss=0.03297, Rate=4202.28 samples/sec, GlobalRate=3906.57 samples/sec
2024-06-11 21:24:14,274 INFO:   | Train Device=CSX, Step=16600, Loss=0.00147, Rate=4199.49 samples/sec, GlobalRate=3908.20 samples/sec
2024-06-11 21:24:15,810 INFO:   | Train Device=CSX, Step=16700, Loss=0.04623, Rate=4179.87 samples/sec, GlobalRate=3909.65 samples/sec
2024-06-11 21:24:17,335 INFO:   | Train Device=CSX, Step=16800, Loss=0.00649, Rate=4189.93 samples/sec, GlobalRate=3911.25 samples/sec
2024-06-11 21:24:18,863 INFO:   | Train Device=CSX, Step=16900, Loss=0.05589, Rate=4188.70 samples/sec, GlobalRate=3912.78 samples/sec
2024-06-11 21:24:20,432 INFO:   | Train Device=CSX, Step=17000, Loss=0.01452, Rate=4123.25 samples/sec, GlobalRate=3913.72 samples/sec
2024-06-11 21:24:21,940 INFO:   | Train Device=CSX, Step=17100, Loss=0.00868, Rate=4196.37 samples/sec, GlobalRate=3915.50 samples/sec
2024-06-11 21:24:23,443 INFO:   | Train Device=CSX, Step=17200, Loss=0.01018, Rate=4232.86 samples/sec, GlobalRate=3917.33 samples/sec
2024-06-11 21:24:24,942 INFO:   | Train Device=CSX, Step=17300, Loss=0.05093, Rate=4254.27 samples/sec, GlobalRate=3919.20 samples/sec
2024-06-11 21:24:26,468 INFO:   | Train Device=CSX, Step=17400, Loss=0.00733, Rate=4218.55 samples/sec, GlobalRate=3920.68 samples/sec
2024-06-11 21:24:27,937 INFO:   | Train Device=CSX, Step=17500, Loss=0.00825, Rate=4302.45 samples/sec, GlobalRate=3922.93 samples/sec
2024-06-11 21:24:29,463 INFO:   | Train Device=CSX, Step=17600, Loss=0.00234, Rate=4236.52 samples/sec, GlobalRate=3924.36 samples/sec
2024-06-11 21:24:30,987 INFO:   | Train Device=CSX, Step=17700, Loss=0.02315, Rate=4214.07 samples/sec, GlobalRate=3925.81 samples/sec
2024-06-11 21:24:32,491 INFO:   | Train Device=CSX, Step=17800, Loss=0.09306, Rate=4239.76 samples/sec, GlobalRate=3927.53 samples/sec
2024-06-11 21:24:34,006 INFO:   | Train Device=CSX, Step=17900, Loss=0.18153, Rate=4230.22 samples/sec, GlobalRate=3929.07 samples/sec
2024-06-11 21:24:35,482 INFO:   | Train Device=CSX, Step=18000, Loss=0.02694, Rate=4293.73 samples/sec, GlobalRate=3931.12 samples/sec
2024-06-11 21:24:37,022 INFO:   | Train Device=CSX, Step=18100, Loss=0.03809, Rate=4210.10 samples/sec, GlobalRate=3932.29 samples/sec
2024-06-11 21:24:38,533 INFO:   | Train Device=CSX, Step=18200, Loss=0.02796, Rate=4226.53 samples/sec, GlobalRate=3933.84 samples/sec
2024-06-11 21:24:40,023 INFO:   | Train Device=CSX, Step=18300, Loss=0.00630, Rate=4267.82 samples/sec, GlobalRate=3935.65 samples/sec
2024-06-11 21:24:41,506 INFO:   | Train Device=CSX, Step=18400, Loss=0.00395, Rate=4296.08 samples/sec, GlobalRate=3937.53 samples/sec
2024-06-11 21:24:43,013 INFO:   | Train Device=CSX, Step=18500, Loss=0.00752, Rate=4265.88 samples/sec, GlobalRate=3939.08 samples/sec
2024-06-11 21:24:44,518 INFO:   | Train Device=CSX, Step=18600, Loss=0.01232, Rate=4257.65 samples/sec, GlobalRate=3940.64 samples/sec
2024-06-11 21:24:46,074 INFO:   | Train Device=CSX, Step=18700, Loss=0.01037, Rate=4171.52 samples/sec, GlobalRate=3941.53 samples/sec
2024-06-11 21:24:47,640 INFO:   | Train Device=CSX, Step=18800, Loss=0.04421, Rate=4121.13 samples/sec, GlobalRate=3942.28 samples/sec
2024-06-11 21:24:49,144 INFO:   | Train Device=CSX, Step=18900, Loss=0.02110, Rate=4200.48 samples/sec, GlobalRate=3943.80 samples/sec
2024-06-11 21:24:50,661 INFO:   | Train Device=CSX, Step=19000, Loss=0.00348, Rate=4211.69 samples/sec, GlobalRate=3945.16 samples/sec
2024-06-11 21:24:52,165 INFO:   | Train Device=CSX, Step=19100, Loss=0.04233, Rate=4237.85 samples/sec, GlobalRate=3946.66 samples/sec
2024-06-11 21:24:53,678 INFO:   | Train Device=CSX, Step=19200, Loss=0.02565, Rate=4233.17 samples/sec, GlobalRate=3948.04 samples/sec
2024-06-11 21:24:55,174 INFO:   | Train Device=CSX, Step=19300, Loss=0.01481, Rate=4260.88 samples/sec, GlobalRate=3949.63 samples/sec
2024-06-11 21:24:56,693 INFO:   | Train Device=CSX, Step=19400, Loss=0.00322, Rate=4232.05 samples/sec, GlobalRate=3950.90 samples/sec
2024-06-11 21:24:58,179 INFO:   | Train Device=CSX, Step=19500, Loss=0.00203, Rate=4277.63 samples/sec, GlobalRate=3952.58 samples/sec
2024-06-11 21:24:59,699 INFO:   | Train Device=CSX, Step=19600, Loss=0.00478, Rate=4236.22 samples/sec, GlobalRate=3953.81 samples/sec
2024-06-11 21:25:01,324 INFO:   | Train Device=CSX, Step=19700, Loss=0.02338, Rate=4058.47 samples/sec, GlobalRate=3953.74 samples/sec
2024-06-11 21:25:02,874 INFO:   | Train Device=CSX, Step=19800, Loss=0.01619, Rate=4099.85 samples/sec, GlobalRate=3954.58 samples/sec
2024-06-11 21:25:04,430 INFO:   | Train Device=CSX, Step=19900, Loss=0.02459, Rate=4107.78 samples/sec, GlobalRate=3955.34 samples/sec
2024-06-11 21:25:05,984 INFO:   | Train Device=CSX, Step=20000, Loss=0.04452, Rate=4114.11 samples/sec, GlobalRate=3956.13 samples/sec
2024-06-11 21:25:05,985 INFO:   Saving checkpoint at step 20000
2024-06-11 21:25:10,291 INFO:   Saved checkpoint /home/kevienzzq/mixed_precision/output/model_dir_mnist/checkpoint_20000.mdl
2024-06-11 21:25:11,866 INFO:   Training completed successfully!
2024-06-11 21:25:11,866 INFO:   Processed 1280000 sample(s) in 323.548901912 seconds.
Total training time: 1281.37 seconds
